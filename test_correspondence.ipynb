{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    print(\"Using MPS\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    print(\"Using GPU\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"No GPU/MPS available, falling back to CPU.\")\n",
    "\n",
    "from diffusion import init_pipe\n",
    "from utils import cosine_similarity, double_plot, get_colors\n",
    "from dino import init_dino\n",
    "from sam2_setup import init_sam2\n",
    "from utils import compute_features, load_mesh\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_views = 50\n",
    "H = 512\n",
    "W = 512\n",
    "tolerance = 0.004\n",
    "use_normal_map = True\n",
    "num_images_per_prompt = 1\n",
    "bq = True\n",
    "use_sam = False\n",
    "use_only_diffusion = False\n",
    "use_diffusion = True\n",
    "is_tosca = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !mkdir -p data/checkpoints\n",
    "# !wget -P data/checkpoints https://dl.fbaipublicfiles.com/segment_anything_2/092824/sam2.1_hiera_large.pt\n",
    "#sam_model = init_sam2(device)\n",
    "sam_model = None\n",
    "pipe = init_pipe(device)\n",
    "dino_model = init_dino(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# please download the data from here into the data folder: https://drive.google.com/drive/folders/1C6lFfCbwQqxlvUE8niVfbeIzeblCnXcx?usp=share_link\n",
    "# pip install gdown && gdown --folder https://drive.google.com/drive/folders/1C6lFfCbwQqxlvUE8niVfbeIzeblCnXcx?usp=share_link\n",
    "\n",
    "source_object_name = \"cow\" # file name .obj\n",
    "source_file_path = f\"data/SHREC20b_lores/models/{source_object_name}.obj\"\n",
    "#source_file_path = f\"data/SHREC20b_lores_tex/{source_object_name}_tex/{source_object_name}_tex.obj\"\n",
    "source_prompt = \"cow\" # prompt for diffusion (e.g. camel instead of camel_a)\n",
    "\n",
    "target_object_name = \"camel_a\"\n",
    "target_file_path = f\"data/SHREC20b_lores/models/{target_object_name}.obj\"\n",
    "#target_file_path = f\"data/SHREC20b_lores_tex/{target_object_name}_tex/{target_object_name}_tex.obj\"\n",
    "target_prompt = \"camel\"\n",
    "\n",
    "\n",
    "source_mesh = load_mesh(source_file_path, device)\n",
    "target_mesh = load_mesh(target_file_path, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = f\"data/rendered_meshes/{source_object_name}_rendered.pt\" # if not None, save batched_renderings, normal_batched_renderings, camera, depth to the specified path\n",
    "f_source = compute_features(device, sam_model, dino_model, pipe, source_mesh, source_prompt, num_views, H, W, tolerance, save_path)\n",
    "\n",
    "save_path = f\"data/rendered_meshes/{target_object_name}_rendered.pt\"\n",
    "f_target = compute_features(device, sam_model, dino_model, pipe, target_mesh, target_prompt, num_views, H, W, tolerance, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing hippo with prompt hippo\n",
      "Processing giraffe_b with prompt giraffe\n",
      "Processing cow with prompt cow\n",
      "Processing giraffe_a with prompt giraffe\n",
      "Processing bison with prompt bison\n",
      "Processing rhino with prompt rhino\n",
      "Processing elephant_a with prompt elephant\n",
      "Processing dog with prompt dog\n",
      "Processing elephant_b with prompt elephant\n",
      "Processing leopard with prompt leopard\n",
      "Processing pig with prompt pig\n",
      "Processing camel_b with prompt camel\n",
      "Processing bear with prompt bear\n",
      "Processing camel_a with prompt camel\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Define the models folder path\n",
    "models_folder_path = \"data/SHREC20b_lores/models\"\n",
    "\n",
    "# Iterate over each object file in the models folder\n",
    "for object_file in os.listdir(models_folder_path):\n",
    "    if object_file.endswith(\".obj\"):\n",
    "        object_name = object_file.split(\".\")[0]\n",
    "        object_file_path = os.path.join(models_folder_path, object_file)\n",
    "        object_prompt = object_name.split(\"_\")[0] \n",
    "        print(f\"Processing {object_name} with prompt {object_prompt}\")\n",
    "\n",
    "\n",
    "        # Load the mesh\n",
    "        object_mesh = load_mesh(object_file_path, device)\n",
    "\n",
    "        # Compute features and save the rendered mesh\n",
    "        save_path = f\"data/rendered_meshes/{object_name}_rendered.pt\"\n",
    "        compute_features(device, sam_model, dino_model, pipe, object_mesh, object_prompt, num_views, H, W, tolerance, save_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = cosine_similarity(f_source.to(device),f_target.to(device))\n",
    "s = torch.argmax(s, dim=0).cpu().numpy()\n",
    "print(dir(source_mesh))\n",
    "print(f\"f_source.shape: {f_source.shape}\")\n",
    "print(f\"f_target.shape: {f_target.shape}\")\n",
    "print(f\"s.shape: {s.shape}\")\n",
    "\n",
    "cmap_source = get_colors(source_mesh.vert); cmap_target = cmap_source[s]\n",
    "\n",
    "double_plot(source_mesh,target_mesh,cmap_source,cmap_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eval import evaluate_meshes\n",
    "\n",
    "s = cosine_similarity(f_target.to(device),f_source.to(device))\n",
    "s = torch.argmax(s, dim=0).cpu().numpy()\n",
    "np.save('predicted_mapping.npy', s)\n",
    "\n",
    "print(f\"f_source.shape: {f_source.shape}\")\n",
    "print(f\"f_target.shape: {f_target.shape}\")\n",
    "print(f\"s.shape: {s.shape}\")\n",
    "\n",
    "# Call the evaluation function\n",
    "avg_error, accuracy, distances = evaluate_meshes(\n",
    "    source_file_path = source_file_path,\n",
    "    target_file_path = target_file_path,\n",
    "    source_gt_path = f'data/SHREC20b_lores_gts/{source_object_name}.mat',\n",
    "    target_gt_path = f'data/SHREC20b_lores_gts/{target_object_name}.mat',\n",
    "    mapping_path = 'predicted_mapping.npy', \n",
    "    debug=False\n",
    ")\n",
    "\n",
    "print(f\"Average correspondence error (err): {avg_error}\")\n",
    "print(f\"Correspondence accuracy (acc, Î³=1%): {accuracy}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eval_batch import run_batch_evaluation\n",
    "\n",
    "# SHREC20b_lores/test-sets/\n",
    "# test-set0.txt - partial-to-full scans\n",
    "# test-set1.txt - full-to-full highest isometry\n",
    "# test-set2.txt - full-to-full high isometry\n",
    "# test-set3.txt - full-to-full low isometry\n",
    "# test-set4.txt - full-to-full lowest isometry\n",
    "\n",
    "# only untextered right now\n",
    "results = run_batch_evaluation(\n",
    "    pairs_file='data/SHREC20b_lores/test-sets/test-set1.txt',\n",
    "    base_path=\"data/SHREC20b_lores\",\n",
    "    device=device,\n",
    "    sam_model=sam_model,\n",
    "    dino_model=dino_model,\n",
    "    pipe=pipe,\n",
    "    num_views=num_views,\n",
    "    H=H,\n",
    "    W=W,\n",
    "    tolerance=tolerance\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diff3f",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
