{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from diff3f import get_features_per_vertex\n",
    "from time import time\n",
    "from utils import convert_mesh_container_to_torch_mesh, cosine_similarity, double_plot, get_colors, generate_colors\n",
    "from dataloaders.mesh_container import MeshContainer\n",
    "from diffusion import init_pipe\n",
    "from dino import init_dino\n",
    "from functional_map import compute_surface_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():  # Fallback to CUDA if available\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    print(\"Using GPU\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")  # Fallback to CPU\n",
    "    print(\"No GPU available, falling back to CPU.\")\n",
    "\n",
    "hw = 256\n",
    "H = hw\n",
    "W = hw\n",
    "num_images_per_prompt = 1\n",
    "tolerance = 0.004\n",
    "random_seed = 42\n",
    "use_normal_map = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_file_path = \"meshes/cow.obj\"\n",
    "target_file_path = \"meshes/camel.obj\"\n",
    "source_mesh = MeshContainer().load_from_file(source_file_path)\n",
    "target_mesh = MeshContainer().load_from_file(target_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from diff3f import VERTEX_GPU_LIMIT, batch_render\n",
    "import random\n",
    "\n",
    "num_views = 100\n",
    "\n",
    "mesh = convert_mesh_container_to_torch_mesh(source_mesh, device=device, is_tosca=False)\n",
    "mesh_vertices = mesh.verts_list()[0]\n",
    "\n",
    "if mesh_vertices is None:\n",
    "    mesh_vertices = mesh.verts_list()[0]\n",
    "\n",
    "if len(mesh_vertices) > VERTEX_GPU_LIMIT:\n",
    "    samples = random.sample(range(len(mesh_vertices)), 10000)\n",
    "    maximal_distance = torch.cdist(mesh_vertices[samples], mesh_vertices[samples]).max()\n",
    "else:\n",
    "    maximal_distance = torch.cdist(mesh_vertices, mesh_vertices).max()  # .cpu()\n",
    "\n",
    "ball_drop_radius = maximal_distance * tolerance\n",
    "\n",
    "batched_renderings, normal_batched_renderings, camera, depth = batch_render(\n",
    "    device, mesh, mesh_vertices, num_views, H, W, use_normal_map,\n",
    "    fixed_angle={'type': 'azimuth', 'value': 0}\n",
    ")\n",
    "\n",
    "print(\"Rendering complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def visualize_rotation_sequence(batched_renderings, num_views, save_video=False):\n",
    "    # Move to CPU and convert to NumPy\n",
    "    batched_renderings = batched_renderings.cpu().numpy()\n",
    "    \n",
    "    if save_video:\n",
    "        import cv2\n",
    "        # Ensure the directory exists\n",
    "        output_path = 'rotation_video.mp4'\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "        out = cv2.VideoWriter(output_path, fourcc, 30.0, (W, H))\n",
    "    \n",
    "    # Visualize each frame\n",
    "    for i in range(num_views):\n",
    "        view = batched_renderings[i]\n",
    "        \n",
    "        if save_video:\n",
    "            # Convert to BGR for OpenCV\n",
    "            frame = (view * 255).astype(np.uint8)\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
    "            out.write(frame)\n",
    "        \n",
    "        # Display every 10th frame to check progression\n",
    "        #if i % 10 == 0:\n",
    "        plt.figure(figsize=(8, 8))\n",
    "        plt.imshow(view)\n",
    "        plt.title(f\"Elevation: {(i/num_views)*360:.1f}Â°\")\n",
    "        plt.axis(\"off\")\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "\n",
    "    if save_video:\n",
    "        out.release()\n",
    "        print(f\"Video saved to {output_path}\")\n",
    "\n",
    "# Use the visualization function\n",
    "visualize_rotation_sequence(batched_renderings, num_views, save_video=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diff3f",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
