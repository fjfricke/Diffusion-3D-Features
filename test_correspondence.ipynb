{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from utils import convert_mesh_container_to_torch_mesh\n",
    "from dataloaders.mesh_container import MeshContainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU available, falling back to CPU.\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    print(\"Using GPU\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"No GPU available, falling back to CPU.\")\n",
    "\n",
    "hw = 1024\n",
    "H = hw\n",
    "W = hw\n",
    "num_images_per_prompt = 1\n",
    "tolerance = 0.004\n",
    "random_seed = 42\n",
    "use_normal_map = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_file_path = \"meshes/cow.obj\"\n",
    "target_file_path = \"meshes/camel.obj\"\n",
    "source_mesh = MeshContainer().load_from_file(source_file_path)\n",
    "target_mesh = MeshContainer().load_from_file(target_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from diff3f import VERTEX_GPU_LIMIT, batch_render\n",
    "import random\n",
    "\n",
    "num_views = 100\n",
    "\n",
    "mesh = convert_mesh_container_to_torch_mesh(source_mesh, device=device, is_tosca=False)\n",
    "mesh_vertices = mesh.verts_list()[0]\n",
    "\n",
    "if mesh_vertices is None:\n",
    "    mesh_vertices = mesh.verts_list()[0]\n",
    "\n",
    "if len(mesh_vertices) > VERTEX_GPU_LIMIT:\n",
    "    samples = random.sample(range(len(mesh_vertices)), 10000)\n",
    "    maximal_distance = torch.cdist(mesh_vertices[samples], mesh_vertices[samples]).max()\n",
    "else:\n",
    "    maximal_distance = torch.cdist(mesh_vertices, mesh_vertices).max()  # .cpu()\n",
    "\n",
    "\n",
    "ball_drop_radius = maximal_distance * tolerance #TODO: check if this is needed\n",
    "\n",
    "\n",
    "batched_renderings, normal_batched_renderings, camera, depth = batch_render(\n",
    "    device=device, \n",
    "    mesh=mesh, \n",
    "    num_views=num_views, \n",
    "    H=H, \n",
    "    W=W, \n",
    "    use_normal_map=use_normal_map, \n",
    "    fixed_angle= {'type': 'elevation', 'value': 0}\n",
    ")\n",
    "\n",
    "batched_renderings_elev, normal_batched_renderings_elev, camera_elev, depth_elev = batch_render(\n",
    "    device=device, \n",
    "    mesh=mesh, \n",
    "    num_views=num_views, \n",
    "    H=H, \n",
    "    W=W, \n",
    "    use_normal_map=use_normal_map, \n",
    "    fixed_angle= {'type': 'azimuth', 'value': 0}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def visualize_rotation_sequence(renderings, num_views, save_video=False):\n",
    "    # Move to CPU and convert to NumPy\n",
    "    renderings = renderings.cpu().numpy()\n",
    "    \n",
    "    if save_video:\n",
    "        import cv2\n",
    "        # Ensure the directory exists\n",
    "        output_path = 'rotation_video.mp4'\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "        out = cv2.VideoWriter(output_path, fourcc, 30.0, (W, H))\n",
    "    \n",
    "    # Visualize each frame\n",
    "    for i in range(num_views):\n",
    "        view = renderings[i]\n",
    "        \n",
    "        if save_video:\n",
    "            # Convert to BGR for OpenCV\n",
    "            frame = (view * 255).astype(np.uint8)\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
    "            out.write(frame)\n",
    "        \n",
    "        # Display every 10th frame to check progression\n",
    "        if i % 1 == 10:\n",
    "            plt.figure(figsize=(8, 8))\n",
    "            plt.imshow(view)\n",
    "            plt.title(f\"Elevation: {(i/num_views)*360:.1f}Â°\")\n",
    "            plt.axis(\"off\")\n",
    "            plt.show()\n",
    "            plt.close()\n",
    "\n",
    "    if save_video:\n",
    "        out.release()\n",
    "        print(f\"Video saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video saved to rotation_video.mp4\n"
     ]
    }
   ],
   "source": [
    "# Use the visualization function\n",
    "combined_renderings = torch.cat([batched_renderings, batched_renderings_elev], axis=0)\n",
    "\n",
    "# visualize_rotation_sequence(batched_renderings, num_views, save_video=True)\n",
    "# visualize_rotation_sequence(batched_renderings_elev, num_views, save_video=False)\n",
    "\n",
    "visualize_rotation_sequence(combined_renderings, num_views*2, save_video=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diff3f",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
