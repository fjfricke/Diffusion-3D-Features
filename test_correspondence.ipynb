{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/miniconda3/envs/diff3f/lib/python3.10/site-packages/transformers/utils/generic.py:311: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    print(\"Using MPS\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    print(\"Using GPU\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"No GPU/MPS available, falling back to CPU.\")\n",
    "\n",
    "from utils import cosine_similarity, double_plot, get_colors\n",
    "from diffusion import init_pipe\n",
    "from dino import init_dino\n",
    "from sam2_setup import init_sam2\n",
    "from utils import compute_features, load_mesh\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_views = 50\n",
    "H = 512\n",
    "W = 512\n",
    "tolerance = 0.004\n",
    "use_normal_map = True\n",
    "num_images_per_prompt = 1\n",
    "bq = True\n",
    "use_sam = False\n",
    "use_only_diffusion = False\n",
    "use_diffusion = False\n",
    "is_tosca = False\n",
    "tex = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46fc278f6885430f817ed6833e196b57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You have disabled the safety checker for <class 'pipeline_controlnet_img2img.StableDiffusionControlNetImg2ImgPipeline'> by passing `safety_checker=None`. Ensure that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered results in services or applications open to the public. Both the diffusers team and Hugging Face strongly recommend to keep the safety filter enabled in all public facing circumstances, disabling it only for use-cases that involve analyzing network behavior or auditing its results. For more information, please have a look at https://github.com/huggingface/diffusers/pull/254 .\n",
      "Using cache found in /root/.cache/torch/hub/facebookresearch_dinov2_main\n",
      "/root/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/swiglu_ffn.py:51: UserWarning: xFormers is not available (SwiGLU)\n",
      "  warnings.warn(\"xFormers is not available (SwiGLU)\")\n",
      "/root/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/attention.py:33: UserWarning: xFormers is not available (Attention)\n",
      "  warnings.warn(\"xFormers is not available (Attention)\")\n",
      "/root/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/block.py:40: UserWarning: xFormers is not available (Block)\n",
      "  warnings.warn(\"xFormers is not available (Block)\")\n"
     ]
    }
   ],
   "source": [
    "# !mkdir -p data/checkpoints\n",
    "# !wget -P data/checkpoints https://dl.fbaipublicfiles.com/segment_anything_2/092824/sam2.1_hiera_large.pt\n",
    "sam_model = None\n",
    "pipe = init_pipe(device)\n",
    "dino_model = init_dino(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading mesh from data/SHREC20b_lores/models/hippo.obj\n",
      "No texture detected. Using MeshContainer.\n",
      "Loading mesh from data/SHREC20b_lores/models/cow.obj\n",
      "No texture detected. Using MeshContainer.\n",
      "\n",
      "Loading mesh from data/SHREC20b_lores_tex/hippo_tex/hippo_tex.obj\n",
      "Detected texture references. Using load_objs_as_meshes.\n",
      "Loading mesh from data/SHREC20b_lores_tex/cow_tex/cow_tex.obj\n",
      "Detected texture references. Using load_objs_as_meshes.\n"
     ]
    }
   ],
   "source": [
    "# please download the data from here into the data folder: https://drive.google.com/drive/folders/1C6lFfCbwQqxlvUE8niVfbeIzeblCnXcx?usp=share_link\n",
    "# pip install gdown && gdown --folder https://drive.google.com/drive/folders/1C6lFfCbwQqxlvUE8niVfbeIzeblCnXcx?usp=share_link\n",
    "\n",
    "source_object_name = \"hippo\" # file name .obj\n",
    "source_file_path = f\"data/SHREC20b_lores/models/{source_object_name}.obj\"\n",
    "source_file_path_tex = f\"data/SHREC20b_lores_tex/{source_object_name}_tex/{source_object_name}_tex.obj\"\n",
    "source_prompt = \"hippo\" # prompt for diffusion (e.g. camel instead of camel_a)\n",
    "\n",
    "target_object_name = \"cow\"\n",
    "target_file_path = f\"data/SHREC20b_lores/models/{target_object_name}.obj\"\n",
    "target_file_path_tex = f\"data/SHREC20b_lores_tex/{target_object_name}_tex/{target_object_name}_tex.obj\"\n",
    "target_prompt = \"cow\"\n",
    "\n",
    "\n",
    "source_mesh = load_mesh(source_file_path, device)\n",
    "target_mesh = load_mesh(target_file_path, device)\n",
    "print()\n",
    "source_tex_mesh = load_mesh(source_file_path_tex, device)\n",
    "target_tex_mesh = load_mesh(target_file_path_tex, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt: hippo\n",
      "num_views: 50\n",
      "use_latent: False\n",
      "use_normal_map: True\n",
      "use_sam: False\n",
      "use_only_diffusion: False\n",
      "use_diffusion: False\n",
      "tex: False\n",
      "Starting batch_render with num_views=50, H=512, W=512\n",
      "Rendering completed successfully\n",
      "Starting batch_render with num_views=50, H=512, W=512\n",
      "Rendering completed successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/miniconda3/envs/diff3f/lib/python3.10/site-packages/torch/functional.py:513: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /home/conda/feedstock_root/build_artifacts/libtorch_1729805341246/work/aten/src/ATen/native/TensorShape.cpp:3609.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'aligned_dino_features' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# save_path = f\"data/rendered_meshes/{source_object_name}_rendered.pt\"\u001b[39;00m\n\u001b[1;32m      2\u001b[0m save_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m f_source \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msam_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdino_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpipe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msource_mesh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msource_prompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_views\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mW\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtolerance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_normal_map\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msource_tex_mesh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_images_per_prompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_sam\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_only_diffusion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_diffusion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_tosca\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m()\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# save_path = f\"data/rendered_meshes/{target_object_name}_rendered.pt\"\u001b[39;00m\n",
      "File \u001b[0;32m/workspace/Diffusion-3D-Features/utils.py:55\u001b[0m, in \u001b[0;36mcompute_features\u001b[0;34m(device, sam_model, dino_model, pipe, mesh_input, prompt, num_views, H, W, tolerance, save_path, use_normal_map, tex, tex_mesh, num_images_per_prompt, bq, use_sam, use_only_diffusion, use_diffusion, is_tosca)\u001b[0m\n\u001b[1;32m     52\u001b[0m mesh_vertices \u001b[38;5;241m=\u001b[39m mesh\u001b[38;5;241m.\u001b[39mverts_list()[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     54\u001b[0m \u001b[38;5;66;03m# Compute features using all available models\u001b[39;00m\n\u001b[0;32m---> 55\u001b[0m features \u001b[38;5;241m=\u001b[39m \u001b[43mget_features_per_vertex\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[43m    \u001b[49m\u001b[43msam_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msam_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpipe\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpipe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdino_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdino_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmesh\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmesh\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_views\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_views\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[43m    \u001b[49m\u001b[43mH\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mH\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m    \u001b[49m\u001b[43mW\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mW\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtolerance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtolerance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_normal_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_normal_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_images_per_prompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_images_per_prompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmesh_vertices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmesh_vertices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_sam\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_sam\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_only_diffusion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_only_diffusion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_diffusion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_diffusion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtex_mesh\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtex_mesh\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m features\u001b[38;5;241m.\u001b[39mcpu()\n",
      "File \u001b[0;32m/workspace/Diffusion-3D-Features/diff3f.py:243\u001b[0m, in \u001b[0;36mget_features_per_vertex\u001b[0;34m(device, sam_model, pipe, dino_model, mesh, prompt, num_views, H, W, tolerance, use_latent, use_normal_map, num_images_per_prompt, mesh_vertices, return_image, bq, prompts_list, use_sam, use_only_diffusion, use_diffusion, save_path, tex, tex_mesh)\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m use_only_diffusion:\n\u001b[1;32m    242\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m use_diffusion:\n\u001b[0;32m--> 243\u001b[0m         aligned_features \u001b[38;5;241m=\u001b[39m \u001b[43maligned_dino_features\u001b[49m\n\u001b[1;32m    244\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    245\u001b[0m         aligned_features \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mhstack([aligned_features\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m0.5\u001b[39m, aligned_dino_features\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m0.5\u001b[39m])\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'aligned_dino_features' referenced before assignment"
     ]
    }
   ],
   "source": [
    "# save_path = f\"data/rendered_meshes/{source_object_name}_rendered.pt\"\n",
    "save_path = None\n",
    "f_source = compute_features(device, sam_model, dino_model, pipe, source_mesh, source_prompt, num_views, H, W, tolerance, \n",
    "    save_path, use_normal_map, tex, source_tex_mesh, num_images_per_prompt, bq, \n",
    "    use_sam, use_only_diffusion, use_diffusion, is_tosca)\n",
    "print()\n",
    "\n",
    "# save_path = f\"data/rendered_meshes/{target_object_name}_rendered.pt\"\n",
    "save_path = None\n",
    "f_target = compute_features(device, sam_model, dino_model, pipe, target_mesh, target_prompt, num_views, H, W, tolerance, \n",
    "    save_path, use_normal_map, tex, target_tex_mesh, num_images_per_prompt, bq, \n",
    "    use_sam, use_only_diffusion, use_diffusion, is_tosca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s = cosine_similarity(f_source.to(device),f_target.to(device))\n",
    "# s = torch.argmax(s, dim=0).cpu().numpy()\n",
    "# print(f\"f_source.shape: {f_source.shape}\")\n",
    "# print(f\"f_target.shape: {f_target.shape}\")\n",
    "# print(f\"s.shape: {s.shape}\")\n",
    "\n",
    "s = np.load(\"hippo_cow_mapping.npy\")\n",
    "cmap_target = get_colors(target_mesh.vert); cmap_source = cmap_target[s]\n",
    "\n",
    "\n",
    "save_path = f\"{target_object_name}_to_{source_object_name}_plot.html\"\n",
    "double_plot(target_mesh, source_mesh, cmap_target, cmap_source, save_path=save_path, show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eval import evaluate_meshes\n",
    "\n",
    "s = cosine_similarity(f_target.to(device),f_source.to(device))\n",
    "s = torch.argmax(s, dim=0).cpu().numpy()\n",
    "np.save('predicted_mapping.npy', s)\n",
    "\n",
    "print(f\"f_source.shape: {f_source.shape}\")\n",
    "print(f\"f_target.shape: {f_target.shape}\")\n",
    "print(f\"s.shape: {s.shape}\")\n",
    "\n",
    "# Call the evaluation function\n",
    "avg_error, accuracy, distances = evaluate_meshes(\n",
    "    source_file_path = source_file_path,\n",
    "    target_file_path = target_file_path,\n",
    "    source_gt_path = f'data/SHREC20b_lores_gts/{source_object_name}.mat',\n",
    "    target_gt_path = f'data/SHREC20b_lores_gts/{target_object_name}.mat',\n",
    "    mapping_path = 'predicted_mapping.npy', \n",
    "    debug=False\n",
    ")\n",
    "\n",
    "avg_error = f\"{avg_error:.2f}\".replace(\".\", \",\")  \n",
    "accuracy = f\"{accuracy * 100:.2f}\".replace(\".\", \",\")\n",
    "\n",
    "print(f\"Average correspondence error (err): {avg_error}\")\n",
    "print(f\"Correspondence accuracy (acc, γ=1%): {accuracy}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eval_batch import run_batch_evaluation\n",
    "\n",
    "# SHREC20b_lores/test-sets/\n",
    "# test-set0.txt - partial-to-full scans\n",
    "# test-set1.txt - full-to-full highest isometry\n",
    "# test-set2.txt - full-to-full high isometry\n",
    "# test-set3.txt - full-to-full low isometry\n",
    "# test-set4.txt - full-to-full lowest isometry\n",
    "\n",
    "# only untextered right now\n",
    "results = run_batch_evaluation(\n",
    "    pairs_file='data/SHREC20b_lores/test-sets/test-set1.txt',\n",
    "    base_path=\"data/SHREC20b_lores\",\n",
    "    device=device,\n",
    "    sam_model=sam_model,\n",
    "    dino_model=dino_model,\n",
    "    pipe=pipe,\n",
    "    num_views=num_views,\n",
    "    H=H,\n",
    "    W=W,\n",
    "    tolerance=tolerance\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
