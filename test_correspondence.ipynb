{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    print(\"Using MPS\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    print(\"Using GPU\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"No GPU/MPS available, falling back to CPU.\")\n",
    "\n",
    "from diffusion import init_pipe\n",
    "from utils import cosine_similarity, double_plot, get_colors\n",
    "from dino import init_dino\n",
    "from sam2_setup import init_sam2\n",
    "from utils import compute_features, load_mesh\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_views = 2\n",
    "H = 512\n",
    "W = 512\n",
    "tolerance = 0.004\n",
    "use_normal_map = True\n",
    "num_images_per_prompt = 1\n",
    "bq = True\n",
    "use_sam = False\n",
    "use_only_diffusion = False\n",
    "use_diffusion = True\n",
    "is_tosca = False\n",
    "\n",
    "save_path=None # if not None, save batched_renderings, normal_batched_renderings, camera, depth to 'rendered_mesh_output.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bfea0cd51994b05b3620985408e52f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You have disabled the safety checker for <class 'pipeline_controlnet_img2img.StableDiffusionControlNetImg2ImgPipeline'> by passing `safety_checker=None`. Ensure that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered results in services or applications open to the public. Both the diffusers team and Hugging Face strongly recommend to keep the safety filter enabled in all public facing circumstances, disabling it only for use-cases that involve analyzing network behavior or auditing its results. For more information, please have a look at https://github.com/huggingface/diffusers/pull/254 .\n",
      "Using cache found in /root/.cache/torch/hub/facebookresearch_dinov2_main\n",
      "/root/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/swiglu_ffn.py:51: UserWarning: xFormers is not available (SwiGLU)\n",
      "  warnings.warn(\"xFormers is not available (SwiGLU)\")\n",
      "/root/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/attention.py:33: UserWarning: xFormers is not available (Attention)\n",
      "  warnings.warn(\"xFormers is not available (Attention)\")\n",
      "/root/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/block.py:40: UserWarning: xFormers is not available (Block)\n",
      "  warnings.warn(\"xFormers is not available (Block)\")\n"
     ]
    }
   ],
   "source": [
    "# !mkdir -p data/checkpoints\n",
    "# !wget -P data/checkpoints https://dl.fbaipublicfiles.com/segment_anything_2/092824/sam2.1_hiera_large.pt\n",
    "#sam_model = init_sam2(device)\n",
    "sam_model = None\n",
    "pipe = init_pipe(device)\n",
    "dino_model = init_dino(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading mesh from data/SHREC20b_lores_tex/hippo_tex/hippo_tex.obj\n",
      "Detected texture references. Using load_objs_as_meshes.\n",
      "Loading mesh from data/SHREC20b_lores_tex/rhino_tex/rhino_tex.obj\n",
      "Detected texture references. Using load_objs_as_meshes.\n"
     ]
    }
   ],
   "source": [
    "# please download the data from here into the data folder: https://drive.google.com/drive/folders/1C6lFfCbwQqxlvUE8niVfbeIzeblCnXcx?usp=share_link\n",
    "# pip install gdown && gdown --folder https://drive.google.com/drive/folders/1C6lFfCbwQqxlvUE8niVfbeIzeblCnXcx?usp=share_link\n",
    "\n",
    "source_object_name = \"hippo\" # file name .obj\n",
    "#source_file_path = f\"data/SHREC20b_lores/models/{source_object_name}.obj\"\n",
    "source_file_path = f\"data/SHREC20b_lores_tex/{source_object_name}_tex/{source_object_name}_tex.obj\"\n",
    "source_prompt = \"hippo\" # prompt for diffusion (e.g. camel instead of camel_a)\n",
    "\n",
    "target_object_name = \"rhino\"\n",
    "#target_file_path = f\"data/SHREC20b_lores/models/{target_object_name}.obj\"\n",
    "target_file_path = f\"data/SHREC20b_lores_tex/{target_object_name}_tex/{target_object_name}_tex.obj\"\n",
    "target_prompt = \"rhino\"\n",
    "\n",
    "\n",
    "source_mesh = load_mesh(source_file_path, device)\n",
    "target_mesh = load_mesh(target_file_path, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting batch_render with num_views=2, H=512, W=512\n",
      "Rendering completed successfully\n",
      "Starting batch_render with num_views=2, H=512, W=512\n",
      "Rendering completed successfully\n",
      "Video saved to output.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/miniconda3/envs/diff3f/lib/python3.10/site-packages/torch/functional.py:513: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /home/conda/feedstock_root/build_artifacts/libtorch_1729805341246/work/aten/src/ATen/native/TensorShape.cpp:3609.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "100%|██████████| 4/4 [00:20<00:00,  5.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing features:  7672\n",
      "Copied features from nearest vertices\n",
      "Time taken in mins:  0.3797622203826904\n",
      "Starting batch_render with num_views=2, H=512, W=512\n",
      "Rendering completed successfully\n",
      "Starting batch_render with num_views=2, H=512, W=512\n",
      "Rendering completed successfully\n",
      "Video saved to output.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:18<00:00,  4.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing features:  8564\n",
      "Copied features from nearest vertices\n",
      "Time taken in mins:  0.3517560283342997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "f_source = compute_features(device, sam_model, dino_model, pipe, source_mesh, source_prompt, num_views, H, W, tolerance, save_path)\n",
    "f_target = compute_features(device, sam_model, dino_model, pipe, target_mesh, target_prompt, num_views, H, W, tolerance, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f_source.shape: torch.Size([11765, 2048])\n",
      "f_target.shape: torch.Size([12395, 2048])\n",
      "s.shape: (12395,)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ea79f92eacd4eb5b20ee4e9899de579",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Output(), Output()))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a699ce5971f407ca097700a5d59c814",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Output(), Output()))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "s = cosine_similarity(f_source.to(device),f_target.to(device))\n",
    "s = torch.argmax(s, dim=0).cpu().numpy()\n",
    "print(f\"f_source.shape: {f_source.shape}\")\n",
    "print(f\"f_target.shape: {f_target.shape}\")\n",
    "print(f\"s.shape: {s.shape}\")\n",
    "\n",
    "cmap_source = get_colors(source_mesh); cmap_target = cmap_source[s]\n",
    "\n",
    "double_plot(source_mesh,target_mesh,cmap_source,cmap_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f_source.shape: torch.Size([11765, 2048])\n",
      "f_target.shape: torch.Size([12395, 2048])\n",
      "s.shape: (11765,)\n",
      "Average correspondence error (err): 0.446379\n",
      "Correspondence accuracy (acc, γ=1%): 0.040816\n"
     ]
    }
   ],
   "source": [
    "from eval import evaluate_meshes\n",
    "\n",
    "s = cosine_similarity(f_target.to(device),f_source.to(device))\n",
    "s = torch.argmax(s, dim=0).cpu().numpy()\n",
    "np.save('predicted_mapping.npy', s)\n",
    "\n",
    "print(f\"f_source.shape: {f_source.shape}\")\n",
    "print(f\"f_target.shape: {f_target.shape}\")\n",
    "print(f\"s.shape: {s.shape}\")\n",
    "\n",
    "# Call the evaluation function\n",
    "avg_error, accuracy, distances = evaluate_meshes(\n",
    "    # source_file_path = f\"data/SHREC20b_lores/models/{source_object_name}.obj\",\n",
    "    source_file_path = source_file_path,\n",
    "    # target_file_path = f\"data/SHREC20b_lores/models/{target_object_name}.obj\",\n",
    "    target_file_path = target_file_path,\n",
    "    source_gt_path = f'data/SHREC20b_lores_gts/{source_object_name}.mat',\n",
    "    target_gt_path = f'data/SHREC20b_lores_gts/{target_object_name}.mat',\n",
    "    mapping_path = 'predicted_mapping.npy', \n",
    "    debug=False\n",
    ")\n",
    "\n",
    "print(f\"Average correspondence error (err): {avg_error:.6f}\")\n",
    "print(f\"Correspondence accuracy (acc, γ=1%): {accuracy:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eval_batch import run_batch_evaluation\n",
    "\n",
    "# SHREC20b_lores/test-sets/\n",
    "# test-set0.txt - partial-to-full scans\n",
    "# test-set1.txt - full-to-full highest isometry\n",
    "# test-set2.txt - full-to-full high isometry\n",
    "# test-set3.txt - full-to-full low isometry\n",
    "# test-set4.txt - full-to-full lowest isometry\n",
    "\n",
    "results = run_batch_evaluation(\n",
    "    pairs_file='data/SHREC20b_lores/test-sets/test-set1.txt',\n",
    "    base_path=\"data/SHREC20b_lores\",\n",
    "    device=device,\n",
    "    sam_model=sam_model,\n",
    "    dino_model=dino_model,\n",
    "    pipe=pipe,\n",
    "    num_views=num_views,\n",
    "    H=H,\n",
    "    W=W,\n",
    "    tolerance=tolerance\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diff3f",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
