{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Using MPS\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    print(\"Using GPU\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"No GPU/MPS available, falling back to CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' from mesh_video_generator import MeshVideoGenerator\\n\\nhw = 1024\\nnum_views = 100\\ndata_dirs = [\"meshes\", \"SHREC19_MH_dataset\", \"SHREC20b_hires/models\", \"MPI-FAUST/training/scans\"]\\n\\ngenerator = MeshVideoGenerator(\\n    output_dir=\"outputs\",\\n    hw=hw,\\n    num_views=num_views,\\n    use_normal_map=True,\\n    device=device\\n) \\ngenerator.process_folder(\"camel_tex\", display_frames=False)\\n#generator.process_single_mesh(\"meshes\", index=5) '"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mesh_video_generator import MeshVideoGenerator\n",
    "\n",
    "hw = 512\n",
    "num_views = 10\n",
    "\n",
    "generator = MeshVideoGenerator(\n",
    "    output_dir=\"outputs\",\n",
    "    hw=hw,\n",
    "    num_views=num_views,\n",
    "    use_normal_map=True,\n",
    "    device=device\n",
    ") \n",
    "generator.process_folder(\"camel_tex\", display_frames=False)\n",
    "#generator.process_single_mesh(\"meshes\", index=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d293ac02ad74e6496f37624a72ba32f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/miniconda3/envs/diff3f/lib/python3.10/site-packages/transformers/utils/generic.py:311: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "#import torch\n",
    "from diff3f import get_features_per_vertex\n",
    "from diffusion import init_pipe\n",
    "\n",
    "from utils import convert_mesh_container_to_torch_mesh, cosine_similarity, double_plot, get_colors\n",
    "from dataloaders.mesh_container import MeshContainer\n",
    "from dino import init_dino\n",
    "from sam2_setup import init_sam2\n",
    "#from functional_map import compute_surface_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_views = 100\n",
    "H = 512\n",
    "W = 512\n",
    "num_images_per_prompt = 1\n",
    "tolerance = 0.004\n",
    "random_seed = 42\n",
    "use_normal_map = True\n",
    "is_tosca = False\n",
    "\n",
    "bq = True\n",
    "use_sam = True\n",
    "use_only_diffusion = False\n",
    "use_diffusion = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_features(device, sam_model, dino_model, pipe, m, prompt, num_views, H, W, tolerance):\n",
    "    # Check if input is already a PyTorch3D Meshes object\n",
    "    if not hasattr(m, 'vert'):  # PyTorch3D Meshes object\n",
    "        mesh = m\n",
    "    else:  # MeshContainer object\n",
    "        mesh = convert_mesh_container_to_torch_mesh(m, device=device, is_tosca=False)\n",
    "    \n",
    "    mesh_vertices = mesh.verts_list()[0]\n",
    "\n",
    "\n",
    "    features = get_features_per_vertex(\n",
    "        device=device,\n",
    "        sam_model=sam_model,\n",
    "        pipe=pipe,\n",
    "        dino_model=dino_model,\n",
    "        mesh=mesh,\n",
    "        prompt=prompt,\n",
    "        num_views=num_views,\n",
    "        H=H,\n",
    "        W=W,\n",
    "        tolerance=tolerance,\n",
    "        use_normal_map= use_normal_map,\n",
    "        num_images_per_prompt=num_images_per_prompt,\n",
    "        mesh_vertices=mesh_vertices,\n",
    "        bq=bq,\n",
    "        use_sam = use_sam,\n",
    "        use_only_diffusion = use_only_diffusion,\n",
    "        use_diffusion = use_diffusion,\n",
    "    )\n",
    "    return features.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7643ac72c86422eb3e955179576c62c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/945 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b754dc4da7ff40aea63ab46bfd1ad43b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)ch_model.safetensors:   0%|          | 0.00/1.45G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8ebb9f1c362441ba400aa1e641c415b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/1.00k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b769edb3b234f84a17087c839bc079b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)ch_model.safetensors:   0%|          | 0.00/1.45G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f3d57cdd93f4431972987a06bb77eba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading unet/config.json:   0%|          | 0.00/743 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fd91312aad8484498a49c6c16b492aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)del.fp16.safetensors:   0%|          | 0.00/1.72G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24bf58d5279e491caae020769fc4ddab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model_index.json:   0%|          | 0.00/541 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "633cf561c6de490da69cfac5e3d33210",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 11 files:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7794a83c3573425fb86930750e32301f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/492M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "398d79d625bb4d0cbed57c70bbc7a159",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)rocessor_config.json:   0%|          | 0.00/342 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3deee154b7d843e1af02981aebb98634",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer/vocab.json:   0%|          | 0.00/1.06M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f34bf7458a614589b01f129db6a52610",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/472 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44898923296b494f89ea3b76fb190e1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cheduler_config.json:   0%|          | 0.00/308 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "002c899f2ed44026a18071f44eb1fd61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer/merges.txt:   0%|          | 0.00/525k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73b6ed23adf24f5b86f1490a61a13f4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)_encoder/config.json:   0%|          | 0.00/617 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24272578531e44b5a33ee5d5bb5cceba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/806 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbc2487119ab4bf3be517ec94d13d066",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)ch_model.safetensors:   0%|          | 0.00/335M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8d1cc2a63ec4c56a08ca30d4008923e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading vae/config.json:   0%|          | 0.00/547 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a18829aeef34e3ca1edaa7b8918e333",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pipeline_controlnet_img2img:You have disabled the safety checker for <class 'pipeline_controlnet_img2img.StableDiffusionControlNetImg2ImgPipeline'> by passing `safety_checker=None`. Ensure that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered results in services or applications open to the public. Both the diffusers team and Hugging Face strongly recommend to keep the safety filter enabled in all public facing circumstances, disabling it only for use-cases that involve analyzing network behavior or auditing its results. For more information, please have a look at https://github.com/huggingface/diffusers/pull/254 .\n",
      "Downloading: \"https://github.com/facebookresearch/dinov2/zipball/main\" to /root/.cache/torch/hub/main.zip\n",
      "/root/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/swiglu_ffn.py:51: UserWarning: xFormers is not available (SwiGLU)\n",
      "  warnings.warn(\"xFormers is not available (SwiGLU)\")\n",
      "/root/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/attention.py:33: UserWarning: xFormers is not available (Attention)\n",
      "  warnings.warn(\"xFormers is not available (Attention)\")\n",
      "/root/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/block.py:40: UserWarning: xFormers is not available (Block)\n",
      "  warnings.warn(\"xFormers is not available (Block)\")\n",
      "Downloading: \"https://dl.fbaipublicfiles.com/dinov2/dinov2_vitb14/dinov2_vitb14_pretrain.pth\" to /root/.cache/torch/hub/checkpoints/dinov2_vitb14_pretrain.pth\n",
      "100%|██████████| 330M/330M [00:03<00:00, 87.2MB/s] \n"
     ]
    }
   ],
   "source": [
    "sam_model = init_sam2(device)\n",
    "pipe = init_pipe(device)\n",
    "dino_model = init_dino(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch3d.io import load_objs_as_meshes\n",
    "\n",
    "source_file_path = \"cow_tex/cow_tex.obj\"\n",
    "target_file_path = \"camel_tex/camel_tex.obj\"\n",
    "\n",
    "source_mesh = load_objs_as_meshes([source_file_path], device=device)\n",
    "target_mesh = load_objs_as_meshes([target_file_path], device=device)\n",
    "\n",
    "# source_mesh = MeshContainer().load_from_file(source_file_path)\n",
    "# target_mesh = MeshContainer().load_from_file(target_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting batch_render with num_views=100, H=512, W=512\n",
      "Rendering completed successfully\n",
      "Starting batch_render with num_views=100, H=512, W=512\n",
      "Rendering completed successfully\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'exit' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#f_source = compute_features(device, sam_model, dino_model, pipe, source_mesh, \"cow\", num_views, H, W, tolerance)\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m f_target \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msam_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdino_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpipe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_mesh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcamel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_views\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mW\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtolerance\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[5], line 11\u001b[0m, in \u001b[0;36mcompute_features\u001b[0;34m(device, sam_model, dino_model, pipe, m, prompt, num_views, H, W, tolerance)\u001b[0m\n\u001b[1;32m      6\u001b[0m     mesh \u001b[38;5;241m=\u001b[39m convert_mesh_container_to_torch_mesh(m, device\u001b[38;5;241m=\u001b[39mdevice, is_tosca\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m      8\u001b[0m mesh_vertices \u001b[38;5;241m=\u001b[39m mesh\u001b[38;5;241m.\u001b[39mverts_list()[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m---> 11\u001b[0m features \u001b[38;5;241m=\u001b[39m \u001b[43mget_features_per_vertex\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43msam_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msam_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpipe\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpipe\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdino_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdino_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmesh\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmesh\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_views\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_views\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mH\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mH\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mW\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mW\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtolerance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtolerance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_normal_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43muse_normal_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_images_per_prompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_images_per_prompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmesh_vertices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmesh_vertices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_sam\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43muse_sam\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_only_diffusion\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43muse_only_diffusion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_diffusion\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43muse_diffusion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m features\u001b[38;5;241m.\u001b[39mcpu()\n",
      "File \u001b[0;32m/workspace/Diffusion-3D-Features/diff3f.py:111\u001b[0m, in \u001b[0;36mget_features_per_vertex\u001b[0;34m(device, sam_model, pipe, dino_model, mesh, prompt, num_views, H, W, tolerance, use_latent, use_normal_map, num_images_per_prompt, mesh_vertices, return_image, bq, prompts_list, use_sam, use_only_diffusion, use_diffusion)\u001b[0m\n\u001b[1;32m    104\u001b[0m render_data \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbatched_renderings\u001b[39m\u001b[38;5;124m'\u001b[39m: batched_renderings,\n\u001b[1;32m    106\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnormal_batched_renderings\u001b[39m\u001b[38;5;124m'\u001b[39m: normal_batched_renderings,\n\u001b[1;32m    107\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcamera\u001b[39m\u001b[38;5;124m'\u001b[39m: camera,\n\u001b[1;32m    108\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdepth\u001b[39m\u001b[38;5;124m'\u001b[39m: depth\n\u001b[1;32m    109\u001b[0m }\n\u001b[1;32m    110\u001b[0m torch\u001b[38;5;241m.\u001b[39msave(render_data, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrender_data.pt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 111\u001b[0m \u001b[43mexit\u001b[49m()\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_normal_map:\n\u001b[1;32m    113\u001b[0m     normal_batched_renderings \u001b[38;5;241m=\u001b[39m normal_batched_renderings\u001b[38;5;241m.\u001b[39mcpu()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'exit' is not defined"
     ]
    }
   ],
   "source": [
    "#f_source = compute_features(device, sam_model, dino_model, pipe, source_mesh, \"cow\", num_views, H, W, tolerance)\n",
    "f_target = compute_features(device, sam_model, dino_model, pipe, target_mesh, \"camel\", num_views, H, W, tolerance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import meshplot as mp\n",
    "\n",
    "\n",
    "def get_colorss(vertices):\n",
    "    \"\"\"Get colors for vertices using their normalized positions as RGB values\"\"\"\n",
    "    # If vertices is a Meshes object, get the vertices tensor and convert to numpy\n",
    "    if hasattr(vertices, 'verts_list'):\n",
    "        vertices = vertices.verts_list()[0].cpu().numpy()\n",
    "    elif torch.is_tensor(vertices):\n",
    "        vertices = vertices.cpu().numpy()\n",
    "    \n",
    "    min_coord, max_coord = np.min(vertices, axis=0, keepdims=True), np.max(vertices, axis=0, keepdims=True)\n",
    "    cmap = (vertices - min_coord)/(max_coord - min_coord)\n",
    "    return cmap\n",
    "\n",
    "def double_plot(myMesh1, myMesh2, cmap1=None, cmap2=None):\n",
    "    # Get vertices and faces from PyTorch3D Meshes if needed\n",
    "    if hasattr(myMesh1, 'verts_list'):\n",
    "        verts1 = myMesh1.verts_list()[0].cpu().numpy()\n",
    "        faces1 = myMesh1.faces_list()[0].cpu().numpy()\n",
    "    else:\n",
    "        verts1 = myMesh1.vert\n",
    "        faces1 = myMesh1.face\n",
    "        \n",
    "    if hasattr(myMesh2, 'verts_list'):\n",
    "        verts2 = myMesh2.verts_list()[0].cpu().numpy()\n",
    "        faces2 = myMesh2.faces_list()[0].cpu().numpy()\n",
    "    else:\n",
    "        verts2 = myMesh2.vert\n",
    "        faces2 = myMesh2.face\n",
    "    \n",
    "    d = mp.subplot(verts1, faces1, c=cmap1, s=[2, 2, 0])\n",
    "    mp.subplot(verts2, faces2, c=cmap2, s=[2, 2, 1], data=d)\n",
    "\n",
    "\n",
    "\n",
    "s = cosine_similarity(f_source.to(device),f_target.to(device))\n",
    "s = torch.argmax(s, dim=0).cpu().numpy()\n",
    "cmap_source = get_colorss(source_mesh.verts_list()[0]); cmap_target = cmap_source[s]\n",
    "double_plot(source_mesh,target_mesh,cmap_source,cmap_target)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
