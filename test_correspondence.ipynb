{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Using MPS\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    print(\"Using GPU\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"No GPU/MPS available, falling back to CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" from mesh_video_generator import MeshVideoGenerator\n",
    "\n",
    "hw = 512\n",
    "num_views = 10\n",
    "\n",
    "generator = MeshVideoGenerator(\n",
    "    output_dir=\"outputs\",\n",
    "    hw=hw,\n",
    "    num_views=num_views,\n",
    "    use_normal_map=True,\n",
    "    device=device\n",
    ") \n",
    "generator.process_folder(\"camel_tex\", display_frames=False)\n",
    "#generator.process_single_mesh(\"meshes\", index=5) \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import torch\n",
    "from diff3f import get_features_per_vertex\n",
    "from diffusion import init_pipe\n",
    "\n",
    "from utils import convert_mesh_container_to_torch_mesh, cosine_similarity, double_plot, get_colors\n",
    "from dataloaders.mesh_container import MeshContainer\n",
    "from dino import init_dino\n",
    "from sam2_setup import init_sam2\n",
    "#from functional_map import compute_surface_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_views = 50\n",
    "H = 512\n",
    "W = 512\n",
    "num_images_per_prompt = 1\n",
    "tolerance = 0.004\n",
    "random_seed = 42\n",
    "use_normal_map = True\n",
    "is_tosca = False\n",
    "\n",
    "bq = True\n",
    "use_sam = False\n",
    "use_only_diffusion = False\n",
    "use_diffusion = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_features(device, sam_model, dino_model, pipe, m, prompt, num_views, H, W, tolerance):\n",
    "    # Check if input is already a PyTorch3D Meshes object\n",
    "    if not hasattr(m, 'vert'):  # PyTorch3D Meshes object\n",
    "        mesh = m\n",
    "    else:  # MeshContainer object\n",
    "        mesh = convert_mesh_container_to_torch_mesh(m, device=device, is_tosca=False)\n",
    "    \n",
    "    mesh_vertices = mesh.verts_list()[0]\n",
    "\n",
    "\n",
    "    features = get_features_per_vertex(\n",
    "        device=device,\n",
    "        sam_model=sam_model,\n",
    "        pipe=pipe,\n",
    "        dino_model=dino_model,\n",
    "        mesh=mesh,\n",
    "        prompt=prompt,\n",
    "        num_views=num_views,\n",
    "        H=H,\n",
    "        W=W,\n",
    "        tolerance=tolerance,\n",
    "        use_normal_map= use_normal_map,\n",
    "        num_images_per_prompt=num_images_per_prompt,\n",
    "        mesh_vertices=mesh_vertices,\n",
    "        bq=bq,\n",
    "        use_sam = use_sam,\n",
    "        use_only_diffusion = use_only_diffusion,\n",
    "        use_diffusion = use_diffusion,\n",
    "    )\n",
    "    return features.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sam_model = init_sam2(device)\n",
    "pipe = init_pipe(device)\n",
    "dino_model = init_dino(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch3d.io import load_objs_as_meshes\n",
    "\n",
    "source_file_path = \"cow_tex/cow_tex.obj\"\n",
    "target_file_path = \"camel_tex/camel_tex.obj\"\n",
    "\n",
    "source_file_path = \"meshes/cow.obj\"\n",
    "target_file_path = \"meshes/camel.obj\"\n",
    "\n",
    "source_file_path = \"SHREC20b_lores/models/cow.obj\"\n",
    "target_file_path = \"SHREC20b_lores/models/camel_a.obj\"\n",
    "\n",
    "# source_mesh = load_objs_as_meshes([source_file_path], device=device)\n",
    "# target_mesh = load_objs_as_meshes([target_file_path], device=device)\n",
    "\n",
    "source_mesh = MeshContainer().load_from_file(source_file_path)\n",
    "target_mesh = MeshContainer().load_from_file(target_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_source = compute_features(device, sam_model, dino_model, pipe, source_mesh, \"cow\", num_views, H, W, tolerance)\n",
    "f_target = compute_features(device, sam_model, dino_model, pipe, target_mesh, \"camel\", num_views, H, W, tolerance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import meshplot as mp\n",
    "\n",
    "def get_colorss(vertices):\n",
    "    \"\"\"Get colors for vertices using their normalized positions as RGB values\"\"\"\n",
    "    # If vertices is a Meshes object, get the vertices tensor and convert to numpy\n",
    "    if hasattr(vertices, 'verts_list'):\n",
    "        vertices = vertices.verts_list()[0].cpu().numpy()\n",
    "    elif torch.is_tensor(vertices):\n",
    "        vertices = vertices.cpu().numpy()\n",
    "    \n",
    "    min_coord, max_coord = np.min(vertices, axis=0, keepdims=True), np.max(vertices, axis=0, keepdims=True)\n",
    "    cmap = (vertices - min_coord)/(max_coord - min_coord)\n",
    "    return cmap\n",
    "\n",
    "def double_plot(myMesh1, myMesh2, cmap1=None, cmap2=None):\n",
    "    # Get vertices and faces from PyTorch3D Meshes if needed\n",
    "    if hasattr(myMesh1, 'verts_list'):\n",
    "        verts1 = myMesh1.verts_list()[0].cpu().numpy()\n",
    "        faces1 = myMesh1.faces_list()[0].cpu().numpy()\n",
    "    else:\n",
    "        verts1 = myMesh1.vert\n",
    "        faces1 = myMesh1.face\n",
    "        \n",
    "    if hasattr(myMesh2, 'verts_list'):\n",
    "        verts2 = myMesh2.verts_list()[0].cpu().numpy()\n",
    "        faces2 = myMesh2.faces_list()[0].cpu().numpy()\n",
    "    else:\n",
    "        verts2 = myMesh2.vert\n",
    "        faces2 = myMesh2.face\n",
    "    \n",
    "    d = mp.subplot(verts1, faces1, c=cmap1, s=[2, 2, 0])\n",
    "    mp.subplot(verts2, faces2, c=cmap2, s=[2, 2, 1], data=d)\n",
    "\n",
    "\n",
    "s = cosine_similarity(f_source.to(device),f_target.to(device))\n",
    "s = torch.argmax(s, dim=0).cpu().numpy()\n",
    "np.savetxt('s.csv', s, delimiter=',', fmt='%d')\n",
    "\n",
    "cmap_source = get_colors(source_mesh.vert); cmap_target = cmap_source[s]\n",
    "double_plot(source_mesh,target_mesh,cmap_source,cmap_target)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
